{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03772216-b949-40ed-af81-1823d7d8dd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "#!pip install tiffslide\n",
    "#import utils_gbm\n",
    "import pickle as pkl\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a77c202-196e-4d3b-a1b7-f65dc83d623c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "non-default argument follows default argument (300711393.py, line 80)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 80\u001b[0;36m\u001b[0m\n\u001b[0;31m    def __init__(self, df_he, embed_phikon=None,embed_novae=None,emb_c=None,df_target,df_emb_clinical) :\u001b[0m\n\u001b[0m                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m non-default argument follows default argument\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import zarr \n",
    "import torch \n",
    "from PIL import Image\n",
    "import torch.utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tifffile\n",
    "import tiffslide\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "\n",
    "import os\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from matplotlib.pyplot import imread\n",
    "import liana as li\n",
    "import decoupler as dc\n",
    "import omnipath\n",
    "import novae\n",
    "\n",
    "from gbmhackathon.utils.visium_functions import normalize_anndata_wrapper\n",
    "from gbmhackathon import MosaicDataset\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 1200\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "def retrieve_visium_embedding(\n",
    "    sample_list = None,\n",
    "    novae_model = \"MICS-Lab/novae-human-0\",\n",
    "    radius_spatial_n = 200, \n",
    "    resolution = \"hires\"\n",
    "):\n",
    "    #Function that retrieves for all the spatial transcriptomic data (visium) the embedded cell types using the novae fundation model\n",
    "\n",
    "    # Loading the needed data\n",
    "    visium_dict = MosaicDataset.load_visium(\n",
    "        sample_list=sample_list,\n",
    "        resolution=resolution)\n",
    "    \n",
    "    # Normalization using the provided tools\n",
    "    visium_obj = normalize_anndata_wrapper(visium_dict, target_sum=1e6)\n",
    "\n",
    "    # Getting key, values of the dict (to work w/ novae)\n",
    "    list_ids = list(visium_obj.keys())\n",
    "    list_anndata = list(visium_obj.values())\n",
    "\n",
    "    print(f\"Considered list id : \\n {list_ids}\")\n",
    "\n",
    "    print(\"___ Computing Spatial Neighbors ___\")\n",
    "    novae.utils.spatial_neighbors(list_anndata, radius=radius_spatial_n, technology =\"visium\")\n",
    "    print(\"DONE\")\n",
    "\n",
    "    print(\"___ Importation of the pretrained model ___\")\n",
    "    model = novae.Novae.from_pretrained(novae_model)\n",
    "    print(model)\n",
    "    print(\"DONE\")\n",
    "\n",
    "    print(\"__ Computing representation __\")\n",
    "    model.compute_representations(list_anndata, accelerator = \"cuda\", num_workers = 4)\n",
    "    print(\"DONE\")\n",
    "    \n",
    "    list_latent = [anndata.obsm[\"novae_latent\"] for anndata in list_anndata]\n",
    "    print(f\"Size latent space = {list_latent[0].shape[1]}\")\n",
    "\n",
    "    ### Add a function to normalize the different keys ?\n",
    "    dict_latent = dict(zip(list_ids, list_latent))\n",
    "\n",
    "    return dict_latent\n",
    "    \n",
    "\n",
    "\n",
    "class custom_dataset(Dataset): \n",
    "            \n",
    "    def __init__(self, df_he, embed_phikon=None,embed_novae=None,emb_c=None,df_target,df_emb_clinical) : \n",
    "           # self.optimus=list_optimus_path## liste de fichiers \n",
    "            self.df_he=df_he\n",
    "            self.processor_phikonv2= AutoImageProcessor.from_pretrained(\"owkin/phikon-v2\")\n",
    "            \n",
    "            self.phikonv2 = AutoModel.from_pretrained(\"owkin/phikon-v2\")\n",
    "            self.phikonv2.to(device)\n",
    "            self.phikonv2.eval()\n",
    "            \n",
    "            #### Chargement des données phikon\n",
    "            if embed_phikon is  None : \n",
    "                    self.matrix_embedds=torch.empty(self.df_he.shape[0],1024) \n",
    "                    for idx in range(self.df_he.shape[0]): \n",
    "                        id_patient = self.df_he.index[idx]\n",
    "            \n",
    "                      \n",
    "                        slide = tiffslide.TiffSlide(self.df_he.loc[id_patient][\"path\"])\n",
    "                    \n",
    "                      \n",
    "                        image = slide.read_region((0, 0), 0, slide.dimensions)\n",
    "                        image = image.convert(\"RGB\")\n",
    "                    \n",
    "                    \n",
    "                        input_phikon = self.processor_phikonv2(image,return_tensors=\"pt\")\n",
    "                        input_phikon = {key: value.to(device) for key, value in input_phikon.items()}\n",
    "                    \n",
    "                        \n",
    "                        with torch.inference_mode():\n",
    "                            outputs = self.phikonv2(**input_phikon)\n",
    "                            features = outputs.last_hidden_state[:, 0, :]  \n",
    "                        self.matrix_embedds[idx,:]=features\n",
    "                        print(idx)\n",
    "            else : \n",
    "                        self.matrix_embedds=embed_phikon\n",
    "            ### Chargement des embeddings novae\n",
    "            if embed_novae is None : \n",
    "                print(\"aucun embed_novae donnée, mais aucune méthode implémernée pour l'obtenir\") \n",
    "                pass\n",
    "            else : \n",
    "\n",
    "                self.embed_novae=embed_novae\n",
    "                \n",
    "            ###Chargement des données emb_c\n",
    "\n",
    "            if emb_c is None : \n",
    "                raise Exception(\"Emb_c n'est pas donné en entrée, mais aucune méthode implémentée dans le dataset\") \n",
    "            else: \n",
    "                self.emb_c=emb_c\n",
    "\n",
    "        \n",
    "                            \n",
    "    def __len__(self) : \n",
    "            return self.df_he.shape[0] -7 ###\n",
    "            \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "         id_patient = self.df_he.index[idx]\n",
    "         if id_patient in [\"HK_G_034a\", \"HK_G_040a\",\"HK_G_095a\",\"HK_G_096b\"] or id_patient in [\"HK_G_071a\",\"HK_G_092b\",\"HK_G_104a\"]: \n",
    "             #Ici, problème : pas de correspondance entre les id d'embeddings, à corriger \n",
    "             \n",
    "             \n",
    "             return None\n",
    "         else : \n",
    "                 \n",
    "             embedding_image=self.matrix_embedds[idx,:]\n",
    "\n",
    "             ##Chargement des données novae\n",
    "             if \"{}_vis\".format(id_patient) in self.embed_novae.keys() : \n",
    "                 \n",
    "                 embedding_novae=self.embed_novae[\"{}_vis\".format(id_patient)]\n",
    "             elif id_patient in self.embed_novae.keys() : \n",
    "             \n",
    "                  embedding_novae=self.embed_novae[id_patient]\n",
    "             else : \n",
    "                 \n",
    "                 print(\"!!!\",id_patient)\n",
    "                 raise Exception(\"impossible de trouver l'id patient\")\n",
    "\n",
    "\n",
    "             ##chargement des embeddings _c \n",
    "             \n",
    "             if id_patient in self.emb_c.keys() : \n",
    "                 \n",
    "                     embedding_c=self.emb_c[id_patient]\n",
    "             else : \n",
    "                 print(\"###\",id_patient)\n",
    "                 return None\n",
    "                                 \n",
    "             return id_patient, embedding_image,embedding_novae,embedding_c\n",
    "\n",
    "\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Collate function qui ignore les éléments `None`.\n",
    "    \n",
    "    Args:\n",
    "        batch (list): Liste des échantillons retournés par le dataset pour un batch.\n",
    "    \n",
    "    Returns:\n",
    "        list ou tuple : Le batch filtré sans les éléments `None`.\n",
    "    \"\"\"\n",
    "   \n",
    "    batch = [item for item in batch if item is not None]\n",
    "\n",
    "   \n",
    "    if len(batch) == 0:\n",
    "        return None  # Vous pouvez aussi lever une exception si nécessaire.\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3d48fc-e0b2-4ae2-a231-906d1b896760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gbmhackathon import MosaicDataset\n",
    "source_dict_mosaic = MosaicDataset.load_tabular()\n",
    "dict_he=source_dict_mosaic[\"he\"] ## source_dict_mosaic[\"he\"]=dict_keys(['HE files', 'H1 features'])\n",
    "HE_files,H1_features=dict_he[\"HE files\"], dict_he[\"H1 features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd4e3a7-bead-4769-a50f-bac2fd35cc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(H1_features) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44c55a4-027b-4ca3-a91f-eb0ccca716f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"novae_emb_dict.pkl\", \"rb\") as f:\n",
    "    emb_novae = pkl.load(f)\n",
    "with open(\"dict_embedding_c.pkl\", \"rb\") as f:\n",
    "    emb_c = pkl.load(f)\n",
    "dset= custom_dataset(HE_files,torch.load(\"tenseur_embedding_phitonv2.pt\"),emb_novae,emb_c) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f8b0b1-8320-40ae-b7eb-cb98b9554a11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(80) : \n",
    "    if dset.__getitem__(i) is None : \n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d861d7a-20b5-4a26-9b4d-9a5342bfbc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f6daad-ae22-438a-9ed7-81a64b1c71f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dloader=DataLoader(dset,collate_fn=utils_gbm.custom_collate_fn,batch_size=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33761e90-3be1-4ae0-ba13-3718db968148",
   "metadata": {},
   "outputs": [],
   "source": [
    "dloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02518df8-6aff-4b67-9407-601eeec724b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(dloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bf3f5a-a1c1-4b0e-a2aa-35bcf69cdea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10) : \n",
    "    a=dset[i]\n",
    "    print(a[1].shape,a[2].shape,a[3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff987610-4bf1-440d-a9ce-1e6e4b046564",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003a1624-6992-4a88-8fb6-9f975921c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet = []\n",
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2210bd8-5a67-400a-b5d8-b0bffda8e8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_gbmhackathon",
   "language": "python",
   "name": "conda_gbmhackathon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
